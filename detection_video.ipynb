{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "\t(h, w) = frame.shape[:2]\n",
    "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
    "\t\t(104.0, 177.0, 123.0))\n",
    "\n",
    "\tfaceNet.setInput(blob)\n",
    "\tdetections = faceNet.forward()\n",
    "\n",
    "\tfaces = []\n",
    "\tlocs = []\n",
    "\tpreds = []\n",
    "\n",
    "\t# loop over the detections\n",
    "\tfor i in range(0, detections.shape[2]):\n",
    "\t\tconfidence = detections[0, 0, i, 2]\n",
    "\n",
    "\t\tif confidence > 0.5:\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
    "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "\t\t\t\n",
    "\t\t\tface = frame[startY:endY, startX:endX]\n",
    "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "\t\t\tface = cv2.resize(face, (224, 224))\n",
    "\t\t\tface = img_to_array(face)\n",
    "\t\t\tface = preprocess_input(face)\n",
    "\n",
    "\t\t\tfaces.append(face)\n",
    "\t\t\tlocs.append((startX, startY, endX, endY))\n",
    "\n",
    "\tif len(faces) > 0:\n",
    "\t\tfaces = np.array(faces, dtype=\"float32\")\n",
    "\t\tpreds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "\treturn (locs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = cv2.VideoCapture('./data/02.mp4')\n",
    "output_video = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n",
      "writing to video\n"
     ]
    }
   ],
   "source": [
    "# load our serialized face detector model from disk\n",
    "prototxtPath = r\"face_detector\\deploy.prototxt\"\n",
    "weightsPath = r\"face_detector\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "maskNet = load_model(\"face_mask_detection.h5\")\n",
    "\n",
    "print(\"[INFO] starting video...\")\n",
    "\n",
    "while True:\n",
    "\t(frame_exists, frame) = vs.read()\n",
    "\tif not frame_exists:\n",
    "\t\tbreak\n",
    "\telse:\n",
    "\t\tframe = imutils.resize(frame, width=400)\n",
    "\n",
    "\t\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\n",
    "\n",
    "\t\tfor (box, pred) in zip(locs, preds):\n",
    "\n",
    "\t\t\t(startX, startY, endX, endY) = box\n",
    "\t\t\tvalue = pred\n",
    "\n",
    "\t\t\tlabel = \"Mask\" if value < 1  else \"No Mask\"\n",
    "\t\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
    "\n",
    "\t\t\tcv2.putText(frame, label, (startX, startY - 10),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "\tcv2.imshow(\"Frame\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\tif output_video is None:\n",
    "\t\tfourcc1 = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\t\toutput_video = cv2.VideoWriter(\"./output/result.avi\", fourcc1, 25,(frame.shape[1], frame.shape[0]), True)\n",
    "\telse:\n",
    "\t\tprint(\"writing to video\")\n",
    "\t\toutput_video.write(frame)\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\t\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6297d360852260ef8c81e78eef5f461360d563418965bf7e4b6f54e341f9bd2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
